<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-English/QuickStart/config_guide">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Configuration Guide | ROLL</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://alibaba.github.io/ROLL/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://alibaba.github.io/ROLL/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://alibaba.github.io/ROLL/docs/English/QuickStart/config_guide"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Configuration Guide | ROLL"><meta data-rh="true" name="description" content="Pipeline Config"><meta data-rh="true" property="og:description" content="Pipeline Config"><link data-rh="true" rel="icon" href="/ROLL/img/logo.png"><link data-rh="true" rel="canonical" href="https://alibaba.github.io/ROLL/docs/English/QuickStart/config_guide"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/English/QuickStart/config_guide" hreflang="en"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/English/QuickStart/config_guide" hreflang="x-default"><link rel="stylesheet" href="/ROLL/assets/css/styles.ee92a1ec.css">
<link rel="preload" href="/ROLL/assets/js/runtime~main.adb523e0.js" as="script">
<link rel="preload" href="/ROLL/assets/js/main.36b13432.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ROLL/"><div class="navbar__logo"><img src="/ROLL/img/logo.png" alt="ROLL Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/ROLL/img/logo.png" alt="ROLL Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">ROLL</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ROLL/docs/English/QuickStart/alicloud_pipeline_quick_start_en">文档</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/alibaba/ROLL" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/ROLL/docs/English/QuickStart/alicloud_pipeline_quick_start_en">English</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/ROLL/docs/English/QuickStart/alicloud_pipeline_quick_start_en">QuickStart</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/English/QuickStart/alicloud_pipeline_quick_start_en">Quickstart: Singel Node based on Alibaba Cloud</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ROLL/docs/English/QuickStart/config_guide">Configuration Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/English/QuickStart/installation">Installation</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/ROLL/docs/English/StepByStep/agent_pipeline_start">StepByStep</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/ROLL/docs/简体中文/快速开始/alicloud_pipeline_quick_start_cn">简体中文</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ROLL/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">English</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">QuickStart</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Configuration Guide</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Configuration Guide</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="pipeline-config">Pipeline Config<a href="#pipeline-config" class="hash-link" aria-label="Direct link to Pipeline Config" title="Direct link to Pipeline Config">​</a></h2><p>Refer to <a href="/ROLL/docs/English/QuickStart/agent_pipeline_start.md">RLVR Pipeline Start</a> and <a href="/ROLL/docs/English/QuickStart/agent_pipeline_start.md">Agentic Pipeline Start</a> for more details about RLVR/Agentic pipeline configurations and reward settings.</p><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">rollout_batch_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">64</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">prompt_length</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2048</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">response_length</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4096</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">num_return_sequences_in_group</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><code>rollout_batch_size</code>: The number of prompt samples to process in each inference batch.</li><li><code>num_return_sequences_in_group</code>: The number of sequences to generate for each prompt. Notice that its value proportionally scales the actual training samples. In other words, the actual training global batch size is equivalent to <code>num_return_sequences_in_group</code> * <code>rollout_batch_size</code>.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="worker-config">Worker Config<a href="#worker-config" class="hash-link" aria-label="Direct link to Worker Config" title="Direct link to Worker Config">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="actortrainactorinfercriticreference">ActorTrain/ActorInfer/Critic/Reference<a href="#actortrainactorinfercriticreference" class="hash-link" aria-label="Direct link to ActorTrain/ActorInfer/Critic/Reference" title="Direct link to ActorTrain/ActorInfer/Critic/Reference">​</a></h3><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">actor_train</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">model_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">dtype</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> bf16</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">disable_gradient_checkpointing</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">False</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">training_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">learning_rate</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.0e-6</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">weight_decay</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">per_device_train_batch_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">gradient_accumulation_steps</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">warmup_steps</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">20</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">data_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">template</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> native</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">file_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> xxx/train.json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">prompt</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> instruction</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">strategy_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> megatron_train  </span><span class="token comment" style="color:#999988;font-style:italic"># deepspeed_train/megatron_train for training</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">tensor_model_parallel_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">pipeline_model_parallel_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">expert_model_parallel_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">infer_batch_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">device_mapping</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">16))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">actor_infer</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">model_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">generating_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">max_new_tokens</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">response_length</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">temperature</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.99</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">strategy_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> vllm  </span><span class="token comment" style="color:#999988;font-style:italic"># vllm/sglang/hf_infer for inference</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">gpu_memory_utilization</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.6</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">block_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">16</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">max_model_len</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">num_gpus_per_worker</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">device_mapping</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">16))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">reference</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">model_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">strategy_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> megatron_infer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">tensor_model_parallel_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">device_mapping</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">16))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><code>device_mapping</code>: The list of device ids to use when training for the worker. Configure for any worker used gpu devices, including <code>actor_train</code>, <code>actor_infer</code>, <code>critic</code> and <code>reference</code>.</li><li><code>num_gpus_per_worker</code>: The number of GPUs assigned per worker. Applicable to <code>actor_infer</code> only.</li><li><code>infer_batch_size</code>: The batch size to used for inference or computing logprobs. </li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="model-arguments-model_args">Model Arguments (<strong>model_args</strong>)<a href="#model-arguments-model_args" class="hash-link" aria-label="Direct link to model-arguments-model_args" title="Direct link to model-arguments-model_args">​</a></h3><ul><li><code>model_args.dtype</code>: Set model dtype as fp32, bf16, or fp16, otherwise use config&#x27;s torch_dtype</li><li><code>model_args.disable_gradient_checkpointing</code>: Disable gradient checkpointing. Applicable only to <code>actor_train</code> when <code>strategy_name</code> is <code>deepspeed_train</code></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-arguments-data_args">Data Arguments (<strong>data_args</strong>)<a href="#data-arguments-data_args" class="hash-link" aria-label="Direct link to data-arguments-data_args" title="Direct link to data-arguments-data_args">​</a></h3><p>Configure data_args under <code>actor_train</code>.</p><ul><li><code>data_args.template</code>: The chat template used for constructing prompts during training and inference. Setting to <code>native</code> utilizes the default chat template <code>tokenizer.apply_chat_template</code> for prompt construction.</li><li><code>data_args.file_name</code>: The file path for training data. Supported formats include JSON, JSONL, and CSV.</li><li><code>data_args.prompt</code>: Which column in the file to use as prompt.</li><li><code>data_args.messages</code>: Which column in the file to use as messages. (conflicts with prompt)</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="generating-arguments-generating_args">Generating Arguments (<strong>generating_args</strong>)<a href="#generating-arguments-generating_args" class="hash-link" aria-label="Direct link to generating-arguments-generating_args" title="Direct link to generating-arguments-generating_args">​</a></h3><p>Configure generating_args under <code>actor_infer</code>.</p><ul><li><code>generating_args.max_new_tokens</code>: The maximum length of the generated text.</li><li><code>generating_args.temperature</code>: The temperature to use for sampling.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="strategy-arguments-strategy_args">Strategy Arguments (<strong>strategy_args</strong>)<a href="#strategy-arguments-strategy_args" class="hash-link" aria-label="Direct link to strategy-arguments-strategy_args" title="Direct link to strategy-arguments-strategy_args">​</a></h3><ul><li><code>strategy_args.strategy_name</code>: The name of training/inference strategy. <code>deepspeed_train</code>/<code>megatron_train</code> for training, <code>vllm</code>/<code>sglang</code>/<code>hf_infer</code> for inference.</li><li><code>strategy_args.strategy_config</code>: The config of training/inference strategy. Will be passed to <code>strategy_name</code>&#x27;s constructor. E.g. <code>strategy_config.tensor_model_parallel_size</code> for <code>megatron_train</code> strategy and <code>strategy_config.gpu_memory_utilization</code> for <code>vllm</code> strategy.</li></ul><p>Commonly used strategy configs are listed below:</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="megatron-strategy-config">Megatron Strategy Config<a href="#megatron-strategy-config" class="hash-link" aria-label="Direct link to Megatron Strategy Config" title="Direct link to Megatron Strategy Config">​</a></h4><ul><li><code>tensor_model_parallel_size</code>: Degree of tensor model parallelism.</li><li><code>pipeline_model_parallel_size</code>: Degree of pipeline model parallelism.</li><li><code>expert_model_parallel_size</code>: Degree of expert model parallelism.</li><li><code>context_parallel_size</code>: Degree of context parallelism.</li><li><code>virtual_pipeline_model_parallel_size</code>: Num of virtual pipeline in a pipeline.</li><li><code>sequence_parallel</code>: Enable sequence parallel optimization.</li><li><code>recompute_granularity</code>: Checkpoint activations to allow for training with larger models, sequences, and batch sizes. It is supported at two granularities 1) full: whole transformer layer is recomputed, 2) selective: core attention part of the transformer layer is recomputed.</li><li><code>moe_layer_recompute</code>: Memory optimization: checkpointing moe_layer to save activation memory.</li><li><code>moe_token_dispatcher_type</code>: The type of token dispatcher to use. Options are &#x27;allgather&#x27; and &#x27;alltoall&#x27;.</li><li><code>moe_grouped_gemm</code>: Enable grouped gemm for moe experts.</li><li><code>moe_shared_expert_overlap</code>: Enable overlapping between shared expert computations and dispatcher communications.</li><li><code>overlap_grad_reduce</code>: If true, overlap grad reduce-scatter with backward compute in distributed optimizer.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="vllm-strategy-config">VLLM Strategy Config<a href="#vllm-strategy-config" class="hash-link" aria-label="Direct link to VLLM Strategy Config" title="Direct link to VLLM Strategy Config">​</a></h3><ul><li><code>gpu_memory_utilization</code>: The fraction of GPU memory to be used for the model executor.</li><li><code>block_size</code>: Token block size for contiguous chunks of tokens.</li><li><code>max_model_len</code>: Model context length. If unspecified, will be automatically derived from the model config.</li><li><code>load_format</code>: The format of the model weights to load. Since there will be a <code>model update</code> in the beginning, this value should can be set to <code>dummy</code>.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="sglang-strategy-config">SGLang Strategy Config<a href="#sglang-strategy-config" class="hash-link" aria-label="Direct link to SGLang Strategy Config" title="Direct link to SGLang Strategy Config">​</a></h4><ul><li><code>mem_fraction_static</code>: Fraction of the free GPU memory used for static memory like model weights and KV cache. Increase it if KV cache building fails. Decrease it if CUDA runs out of memory.</li><li><code>load_format</code>: The format of the model weights to load. Since there will be a <code>model update</code> in the beginning, this value should can be set to <code>dummy</code>.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="deepspeed-strategy-config">DeepSpeed Strategy Config<a href="#deepspeed-strategy-config" class="hash-link" aria-label="Direct link to DeepSpeed Strategy Config" title="Direct link to DeepSpeed Strategy Config">​</a></h4><p>There are DeepSpeed configurations in <code>./examples/config/</code> that can be overridden in the default list for strategy configuration.</p><p>For example, to use the deepspeed_zero2 strategy, add the following to your config:</p><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">defaults</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> ../config/envs@_here_</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> ../config/deepspeed_zero@_here_</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> ../config/deepspeed_zero2@_here_</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> ../config/deepspeed_zero3@_here_</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> ../config/deepspeed_zero3_cpuoffload@_here_</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">actor_train</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">strategy_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> deepspeed_train</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">deepspeed_zero2</span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="training-arguments-training_args">Training Arguments (<strong>training_args</strong>)<a href="#training-arguments-training_args" class="hash-link" aria-label="Direct link to training-arguments-training_args" title="Direct link to training-arguments-training_args">​</a></h3><p>Used for configuring training parameters such as <code>learning_rate</code>, <code>weight_decay</code>, <code>warmup_steps</code>, etc.</p><ul><li><code>training_args.per_device_train_batch_size</code>: The batch size to use when training.</li><li><code>training_args.gradient_accumulation_steps</code>: The number of gradient accumulation steps.</li></ul><p>In deepspeed training the global train batch size is <code>per_device_train_batch_size</code> <!-- -->*<!-- --> <code>gradient_accumulation_steps</code> <!-- -->*<!-- --> world_size (a.k.a length of <code>device_mapping</code> for <code>actor_train</code>/<code>critic</code>).</p><p>In megatron training the global train batch size is <code>per_device_train_batch_size</code> <!-- -->*<!-- --> <code>gradient_accumulation_steps</code> <!-- -->*<!-- --> world_size / <code>tensor_model_parallel_size</code> / <code>pipeline_model_parallel_size</code> / <code>context_parallel_size</code> (don&#x27;t need to divide <code>expert_model_parallel_size</code>).</p><p>If you want to perform one optimization step in each rollout, set <code>gradient_accumulation_steps</code> to <code>rollout_batch_size</code> <!-- -->*<!-- --> <code>num_return_sequences_in_group</code> <!-- -->*<!-- --> <code>tensor_model_parallel_size</code> <!-- -->*<!-- --> <code>pipeline_model_parallel_size</code> <!-- -->*<!-- --> <code>context_parallel_size</code>/ <code>per_device_train_batch_size</code> / world_size.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/English/QuickStart/config_guide.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ROLL/docs/English/QuickStart/alicloud_pipeline_quick_start_en"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Quickstart: Singel Node based on Alibaba Cloud</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ROLL/docs/English/QuickStart/installation"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Installation</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#pipeline-config" class="table-of-contents__link toc-highlight">Pipeline Config</a></li><li><a href="#worker-config" class="table-of-contents__link toc-highlight">Worker Config</a><ul><li><a href="#actortrainactorinfercriticreference" class="table-of-contents__link toc-highlight">ActorTrain/ActorInfer/Critic/Reference</a></li><li><a href="#model-arguments-model_args" class="table-of-contents__link toc-highlight">Model Arguments (<strong>model_args</strong>)</a></li><li><a href="#data-arguments-data_args" class="table-of-contents__link toc-highlight">Data Arguments (<strong>data_args</strong>)</a></li><li><a href="#generating-arguments-generating_args" class="table-of-contents__link toc-highlight">Generating Arguments (<strong>generating_args</strong>)</a></li><li><a href="#strategy-arguments-strategy_args" class="table-of-contents__link toc-highlight">Strategy Arguments (<strong>strategy_args</strong>)</a></li><li><a href="#vllm-strategy-config" class="table-of-contents__link toc-highlight">VLLM Strategy Config</a></li><li><a href="#training-arguments-training_args" class="table-of-contents__link toc-highlight">Training Arguments (<strong>training_args</strong>)</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Examples</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ROLL/docs/简体中文/StepByStep/alicloud_pipeline_quick_start_cn">阿里云ROLL实践手册</a></li><li class="footer__item"><a class="footer__link-item" href="/ROLL/docs/简体中文/快速开始/config_guide_cn">配置指南</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/alibaba/ROLL" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Alibaba.</div></div></div></footer></div>
<script src="/ROLL/assets/js/runtime~main.adb523e0.js"></script>
<script src="/ROLL/assets/js/main.36b13432.js"></script>
</body>
</html>
<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-简体中文/快速开始/config_guide_cn">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">配置指南 | ROLL</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://alibaba.github.io/ROLL/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://alibaba.github.io/ROLL/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://alibaba.github.io/ROLL/docs/简体中文/快速开始/config_guide_cn"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="配置指南 | ROLL"><meta data-rh="true" name="description" content="Pipeline配置"><meta data-rh="true" property="og:description" content="Pipeline配置"><link data-rh="true" rel="icon" href="/ROLL/img/logo.png"><link data-rh="true" rel="canonical" href="https://alibaba.github.io/ROLL/docs/简体中文/快速开始/config_guide_cn"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/简体中文/快速开始/config_guide_cn" hreflang="en"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/简体中文/快速开始/config_guide_cn" hreflang="x-default"><link rel="stylesheet" href="/ROLL/assets/css/styles.ee92a1ec.css">
<link rel="preload" href="/ROLL/assets/js/runtime~main.09d68117.js" as="script">
<link rel="preload" href="/ROLL/assets/js/main.b3aa004e.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ROLL/"><div class="navbar__logo"><img src="/ROLL/img/logo.png" alt="ROLL Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/ROLL/img/logo.png" alt="ROLL Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">ROLL</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ROLL/docs/English/QuickStart/config_guide">文档</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/alibaba/ROLL" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/ROLL/docs/English/QuickStart/config_guide">English</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/ROLL/docs/简体中文/快速开始/config_guide_cn">简体中文</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/ROLL/docs/简体中文/快速开始/config_guide_cn">快速开始</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ROLL/docs/简体中文/快速开始/config_guide_cn">配置指南</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/简体中文/快速开始/metrics_info_cn">实验数据分析与查看</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/简体中文/快速开始/multi_nodes_quick_start_cn">快速上手：多节点部署指南</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/简体中文/快速开始/single_node_quick_start_cn">快速上手：单机版部署指南</a></li></ul></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ROLL/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">简体中文</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">快速开始</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">配置指南</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>配置指南</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="pipeline配置">Pipeline配置<a href="#pipeline配置" class="hash-link" aria-label="Direct link to Pipeline配置" title="Direct link to Pipeline配置">​</a></h2><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">exp_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;agentic_pipeline&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">seed</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">42</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">rpc_timeout</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">3600</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">logging_dir</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ./output/logs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">output_dir</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ./output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">render_save_dir</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /data/oss_bucket_0/yali/output/render</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">system_envs</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">USE_MODELSCOPE</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;1&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">track_with</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> tensorboard</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">tracker_kwargs</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">log_dir</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /data/oss_bucket_0/yali/llm/tensorboard/roll_exp/agentic_sokoban</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">num_gpus_per_node</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">max_steps</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1024</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">save_steps</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">logging_steps</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">eval_steps</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">resume_from_checkpoint</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">false</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">rollout_batch_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">64</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">prompt_length</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2048</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">response_length</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4096</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">num_return_sequences_in_group</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="基本信息与通用配置">基本信息与通用配置<a href="#基本信息与通用配置" class="hash-link" aria-label="Direct link to 基本信息与通用配置" title="Direct link to 基本信息与通用配置">​</a></h3><ul><li><code>exp_name</code>: 当前实验的名称，用于标识和组织输出文件、日志等。默认是从 Python 文件名派生。</li><li><code>seed</code>:  用于初始化随机数生成器。设置固定的种子可以确保实验的可复现性。</li><li><code>rpc_timeout</code>: 远程过程调用（RPC）的超时时长，单位为秒。用于 Ray Actor 之间通信。如果一个调用在此时间内没有响应，则会抛出超时错误。</li><li><code>output_dir</code>: 模型预测结果和检查点（checkpoints）的输出目录。</li><li><code>logging_dir</code>: 存储日志文件的目录。</li><li><code>track_with</code>:  用于跟踪实验进度的工具类型。可选 wandb (Weights &amp; Biases), tensorboard (TensorBoard), 或 stdout (标准输出)。</li><li><code>tracker_kwargs</code>:  传递给所选跟踪器类的额外关键字参数（字典）。例如，WandB 的 API 密钥、项目名称等。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="训练评估流程配置">训练/评估流程配置<a href="#训练评估流程配置" class="hash-link" aria-label="Direct link to 训练/评估流程配置" title="Direct link to 训练/评估流程配置">​</a></h3><ul><li><code>max_steps</code>: 训练的最大步数。如果大于 0，则设置流水线执行的总步数。训练将在达到此步数时停止。</li><li><code>save_steps</code>: 保存模型检查点的频率。每隔 X 个更新步数保存一次模型检查点。</li><li><code>logging_steps</code>: 记录训练指标的频率。每隔 X 个更新步数记录一次训练信息（例如损失、指标等）。</li><li><code>eval_steps</code>: 评估频率。每隔 X 个更新步数执行一次评估。</li><li><code>resume_from_checkpoint</code>: 是否从检查点恢复训练。如果设置为 True，则从 output_dir 中最近的检查点恢复。</li><li><code>checkpoint_config</code>: 检查点相关的配置信息，这个字段会被写入 worker_config。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="批处理大小与序列长度配置">批处理大小与序列长度配置<a href="#批处理大小与序列长度配置" class="hash-link" aria-label="Direct link to 批处理大小与序列长度配置" title="Direct link to 批处理大小与序列长度配置">​</a></h3><ul><li><code>rollout_batch_size</code>: 在每次推理批次中，要进行 Rollout 的样本数量。</li><li><code>val_batch_size</code>: 在每次验证批次中，要进行 Rollout 的样本数量。</li><li><code>prompt_length</code>: 提示（输入）的最大长度（以 token 为单位）。如果实际提示更短，会填充到此长度；如果更长，可能会被截断。</li><li><code>response_length</code>: LLM 生成的响应（输出）的最大长度（以 token 为单位）。如果 LLM 生成的响应更短，会填充；如果更长，会被截断。</li><li><code>sequence_length</code>: 要填充的最大序列长度（以 token 为单位）。这通常指 LLM 模型的总上下文窗口大小，包括提示和生成的响应。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="分布式训练配置">分布式训练配置<a href="#分布式训练配置" class="hash-link" aria-label="Direct link to 分布式训练配置" title="Direct link to 分布式训练配置">​</a></h3><ul><li><code>local_rank</code>: 分布式训练中的本地排名（在当前节点内的排名）。对于分布式训练，通常由系统自动设置；如果不是分布式训练，则设置为 -1。</li><li><code>num_nodes</code>: 可用于分布式训练的节点（物理服务器）数量。如果设置为 1，则表示在单个节点上进行分布式训练。</li><li><code>num_gpus_per_node</code>: 指定每个节点上可用的 GPU 数量。当节点数量大于 1 时，此参数应请求整个节点上的 GPU 总数。确保在多节点设置中 GPU 资源分配与请求一致。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="调度与请求管理">调度与请求管理<a href="#调度与请求管理" class="hash-link" aria-label="Direct link to 调度与请求管理" title="Direct link to 调度与请求管理">​</a></h3><ul><li><code>generate_opt_level</code>:  控制 LLM 生成（推理）的优化级别。设置为 0 时，使用基础批次生成接口；设置为 1 时，使用调度器处理请求。</li><li><code>is_num_return_sequences_expand</code>: 是否在提示（prompts）中复制 num_return_sequences 次。如果为 True，LLM 会为每个输入提示生成多个独立的响应，而不是只生成一个。</li><li><code>max_running_requests</code>: 在 LLM 推理服务器上可以同时处理的最大请求数量。这限制了并行推理的并发度。</li><li><code>is_use_additional_prompts</code>: 是否使用除常规批次大小之外的额外提示进行处理。</li><li><code>max_additional_running_prompts</code>: 在 batch_size 之外，可以额外运行的提示数量。这可能用于处理一些特殊或低优先级的请求，而不会阻塞主批次。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="rlvr-pipeline-常用配置">RLVR Pipeline 常用配置<a href="#rlvr-pipeline-常用配置" class="hash-link" aria-label="Direct link to RLVR Pipeline 常用配置" title="Direct link to RLVR Pipeline 常用配置">​</a></h3><ul><li><code>num_return_sequences_in_group</code>: 对于每个提示，LLM 要生成序列的数量。请注意，它的值会按比例扩大实际的训练全局批次样本量。换句话说，实际的训练全局批次大小等于 <code>num_return_sequences_in_group</code> * <code>rollout_batch_size</code>。</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="ppo算法核心参数">PPO算法核心参数<a href="#ppo算法核心参数" class="hash-link" aria-label="Direct link to PPO算法核心参数" title="Direct link to PPO算法核心参数">​</a></h4><ul><li><code>ppo_epochs</code>: 每个样本批次（即收集到一批经验数据后）进行优化的迭代次数。在一个 PPO 训练循环中，Agent 首先收集数据，然后利用这些数据进行多次梯度更新。</li><li><code>max_grad_norm</code>: 梯度裁剪的最大范数。用于防止梯度爆炸。</li><li><code>l2</code>: L2 正则化系数，用于惩罚大的权重值以防止过拟合。</li><li><code>lambd</code>: 广义优势估计（GAE, Generalized Advantage Estimation）中的 lambda 参数。控制偏差-方差权衡。值接近 1 减少方差，值接近 0 减少偏差。</li><li><code>gamma</code>: 强化学习中的折扣因子。用于折算未来奖励的重要性。值越接近 1，模型越重视长期奖励。</li><li><code>kl_penalty</code>: KL 散度惩罚的计算方式。KL 散度用于衡量新旧策略之间的差异，防止策略更新过大。<ul><li>&#x27;kl&#x27;: model_logp - ref_logp (新策略 log 概率减去参考策略 log 概率)。</li><li>&#x27;abs&#x27;: abs(kl) (KL 散度的绝对值)。</li><li>&#x27;mse&#x27;: mse(kl) (KL 散度的均方误差)。</li><li>&#x27;full&#x27;: 分布中所有 token 的实际 KL 散度。</li></ul></li><li><code>init_kl_coef</code>: 初始的 KL 惩罚系数（用于自适应和线性控制）。这个系数乘以 KL 散度项，作为损失的一部分。</li><li><code>kl_horizon</code>: 自适应 KL 控制的周期。</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="ppo奖励优势处理">PPO奖励/优势处理<a href="#ppo奖励优势处理" class="hash-link" aria-label="Direct link to PPO奖励/优势处理" title="Direct link to PPO奖励/优势处理">​</a></h4><ul><li><code>use_reward_scaling</code>: 是否对奖励进行缩放。</li><li><code>add_len_reward</code>: 是否添加基于序列长度的奖励。</li><li><code>reward_clip</code>: 对奖励进行裁剪的值，防止极端奖励影响训练。</li><li><code>difficulty_loss_weight</code>: 是否使用难度损失权重。</li><li><code>length_loss_weight</code>: 是否使用长度损失权重。</li><li><code>use_reward_norm</code>: 是否使用奖励归一化。仅当 use_reward_scaling 为 True 时适用。</li><li><code>whiten_rewards</code>: 在计算优势值之前，是否对奖励进行白化处理（使其均值为 0，方差为 1）。</li><li><code>whiten_advantages</code>: 是否对优势值进行白化处理。有助于稳定训练。</li><li><code>advantage_clip</code>: 优势值裁剪的范围。</li><li><code>adv_estimator</code>: 优势值的估计方法。<ul><li>&#x27;gae&#x27;: 广义优势估计（GAE）。</li><li>&#x27;reinforce&#x27;: REINFORCE 算法中的优势估计。</li><li>&#x27;grpo&#x27;: Gated Recurrent Policy Optimization 中的优势估计。</li></ul></li><li><code>reward_norm</code>: 奖励归一化的方式。<ul><li>&#x27;batch&#x27;: 对批次内的所有奖励进行归一化。</li><li>&#x27;group&#x27;: 在提示组内部进行归一化。</li><li>&#x27;running&#x27;: 使用动态更新的统计量进行归一化。</li><li>None: 不进行归一化。</li></ul></li><li><code>reward_shift</code>: 在奖励归一化时，是否只减去均值而不除以标准差。</li><li><code>reward_scale</code>: 在奖励归一化时，是否只除以标准差而不减去均值。</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="ppo-损失函数组件">PPO 损失函数组件<a href="#ppo-损失函数组件" class="hash-link" aria-label="Direct link to PPO 损失函数组件" title="Direct link to PPO 损失函数组件">​</a></h4><ul><li><code>add_token_level_kl</code>: 是否添加 token 级别的 KL 散度惩罚。</li><li><code>critic_warmup</code>: Critic 模型在正式训练开始前的预训练步数。</li><li><code>use_kl_loss</code>: 是否使用 KL 散度损失。</li><li><code>kl_loss_coef</code>: KL 散度损失项的系数。</li><li><code>entropy_loss_coef</code>: 熵损失项的系数。增加熵可以鼓励策略探索。</li><li><code>sft_loss_coef</code>: SFT (Supervised Fine-tuning) 损失的系数，用于正样本（例如，如果有监督微调的数据）。</li><li><code>use_topr_loss</code>: 是否使用 TPRO (Trigonometric Policy Regularization with Offset) 损失。</li><li><code>rl_loss_coef</code>: 强化学习损失项的系数。</li><li><code>dual_clip_loss</code>: 是否使用双裁剪损失。PPO 损失函数的一种变体。</li><li><code>loss_agg_mode</code>: 损失聚合的方式。<ul><li>&#x27;token-mean&#x27;: Token 级别的均值。</li><li>&#x27;seq-mean-token-sum&#x27;: 序列级别的均值，token 级别的求和。</li><li>&#x27;seq-mean-token-mean&#x27;: 序列级别和 token 级别的均值。</li><li>&#x27;seq-mean-token-sum-norm&#x27;: 序列级别的均值，token 级别的归一化求和。</li></ul></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agentic-pipeline-配置">Agentic Pipeline 配置<a href="#agentic-pipeline-配置" class="hash-link" aria-label="Direct link to Agentic Pipeline 配置" title="Direct link to Agentic Pipeline 配置">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="奖励归一化配置">奖励归一化配置<a href="#奖励归一化配置" class="hash-link" aria-label="Direct link to 奖励归一化配置" title="Direct link to 奖励归一化配置">​</a></h4><ul><li><code>grouping</code>: 定义奖励归一化时的分组方式，可选 &#x27;state&#x27;、&#x27;batch&#x27;和&#x27;inductive&#x27;。</li><li><code>method</code>: 定义具体的归一化方法，可选 &#x27;asym_clip&#x27;、&#x27;identity&#x27;和&#x27;mean_std&#x27;。</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="环境管理器配置">环境管理器配置<a href="#环境管理器配置" class="hash-link" aria-label="Direct link to 环境管理器配置" title="Direct link to 环境管理器配置">​</a></h4><ul><li>env_groups: 训练期间环境组的数量。每个环境组可能并行运行。</li><li>group_size: 在同一个组内，环境配置和环境种子（prompt）被确保是相同的。这对于控制实验变量和确保可复现性很重要。</li><li>tags: 环境的标签列表，用于标识和选择要使用的环境类型（例如 &quot;SimpleSokoban&quot;）。</li><li>n_groups: 如果未设置，所有环境名称将平均分配到组中。在同一个组中，环境配置和环境种子（prompt）在每次生成中都是相同的。</li><li>max_traj_per_env: 每个环境可以 Rollout 的最大轨迹数量。-1 表示没有限制。</li><li>format_penalty: 当 LLM 生成的响应不符合预期格式时所施加的惩罚值。这是一个负值，会降低不合格响应的奖励。</li><li>worker_cls: 环境管理器将使用的具体工作器类的路径。这个类实现了环境交互的逻辑。</li></ul><p>有关 RLVR/Agentic Pipeline配置和Reward设置的更多详细信息，还可以参阅 <a href="/ROLL/docs/english/examples/agent_pipeline_start.md">RLVR Pipeline Start</a> 和 <a href="/ROLL/docs/english/examples/agent_pipeline_start.md">Agentic Pipeline Start</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="worker配置">Worker配置<a href="#worker配置" class="hash-link" aria-label="Direct link to Worker配置" title="Direct link to Worker配置">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="actortrainactorinfercriticreference">ActorTrain/ActorInfer/Critic/Reference<a href="#actortrainactorinfercriticreference" class="hash-link" aria-label="Direct link to ActorTrain/ActorInfer/Critic/Reference" title="Direct link to ActorTrain/ActorInfer/Critic/Reference">​</a></h3><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">actor_train</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">model_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">dtype</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> bf16</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">disable_gradient_checkpointing</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">False</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">training_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">learning_rate</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.0e-6</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">weight_decay</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">per_device_train_batch_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">gradient_accumulation_steps</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">warmup_steps</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">20</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">data_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">template</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> native</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">file_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> xxx/train.json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">prompt</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> instruction</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">strategy_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> megatron_train  </span><span class="token comment" style="color:#999988;font-style:italic"># 训练策略：deepspeed_train 或 megatron_train</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">tensor_model_parallel_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">pipeline_model_parallel_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">expert_model_parallel_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">infer_batch_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">device_mapping</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">16))  </span><span class="token comment" style="color:#999988;font-style:italic"># 使用的设备 ID 列表</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">actor_infer</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">model_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">generating_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">max_new_tokens</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">response_length</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">temperature</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.99</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">strategy_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> vllm  </span><span class="token comment" style="color:#999988;font-style:italic"># 推理策略：vllm, sglang 或 hf_infer</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">gpu_memory_utilization</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.6</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">block_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">16</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">max_model_len</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">num_gpus_per_worker</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># 每个 worker 分配的 GPU 数量</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">device_mapping</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">16))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">reference</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">model_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">strategy_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> megatron_infer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">tensor_model_parallel_size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">device_mapping</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">16))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><code>world_size</code>: 参与这个特定角色集群的总数量。例如，如果有多个 actor_train 实例，这就是它们的总数。</li><li><code>device_mapping</code>: 当 worker 进行训练时要使用的设备 ID 列表。 配置所有使用 GPU 的 worker，包括<code>actor_train</code>、<code>actor_infer</code>、<code>critic</code> 和 <code>reference</code>。例如 list(range(0,16)) 表示使用 ID 为 0 到 15 的 GPU。</li><li><code>num_gpus_per_worker</code>: 分配给每个 worker 的 GPU 数量。 仅适用于<code>actor_infer</code>。如果一个 actor_infer 需要多个 GPU（例如用于模型并行），则设置此参数。</li><li><code>model_update_frequency</code>: 模型更新的频率。例如，每多少步或每多少个事件触发一次模型更新。</li><li><code>infer_batch_size</code>: 用于推理或计算 logprobs 时的批次大小。 这通常是单个推理请求的内部批次大小。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="模型参数-model_args">模型参数 (<strong>model_args</strong>)<a href="#模型参数-model_args" class="hash-link" aria-label="Direct link to 模型参数-model_args" title="Direct link to 模型参数-model_args">​</a></h3><ul><li><code>model_args.dtype</code>: 设置模型的数据类型，可以是 fp32 (单精度浮点数), bf16 (BFloat16), 或 fp16 (半精度浮点数)。如果不设置，则使用配置的 torch_dtype。选择合适的数据类型可以平衡计算速度、内存消耗和精度。</li><li><code>model_args.disable_gradient_checkpointing</code>: 禁用梯度检查点。仅当 <code>actor_train</code> 的 <code>strategy_name</code> 为 <code>deepspeed_train</code> 时适用。梯度检查点是一种内存优化技术，通过在反向传播时重新计算部分激活值来减少显存占用。禁用它会增加内存消耗但可能略微加速计算。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="数据参数-data_args">数据参数 (<strong>data_args</strong>)<a href="#数据参数-data_args" class="hash-link" aria-label="Direct link to 数据参数-data_args" title="Direct link to 数据参数-data_args">​</a></h3><p>如何配置<code>actor_train</code>下的 data_args：</p><ul><li><code>data_args.template</code>: 用于在训练和推理期间构建提示的聊天模板。设置为<code>native</code>时，将使用分词器（tokenizer）的默认聊天模板<code>tokenizer.apply_chat_template</code>来构建提示。</li><li><code>data_args.file_name</code>: 训练数据的文件路径。支持的格式包括 JSON、JSONL 和 CSV。</li><li><code>data_args.prompt</code>: 在数据文件中用作提示的列名。</li><li><code>data_args.messages</code>: 在数据文件中用作消息的列名（与 prompt 冲突，两者只能选其一）。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="生成参数-generating_args">生成参数 (<strong>generating_args</strong>)<a href="#生成参数-generating_args" class="hash-link" aria-label="Direct link to 生成参数-generating_args" title="Direct link to 生成参数-generating_args">​</a></h3><p>如何配置<code>actor_infer</code>下的 generating_args：</p><ul><li><code>generating_args.max_new_tokens</code>: 生成文本的最大长度（以 token 为单位）。这限制了 LLM 每次推理调用可以输出多少新内容。</li><li><code>generating_args.temperature</code>: 用于采样的温度值。较高的温度会使生成结果更随机、更有创造性；较低的温度会使结果更确定、更保守。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="策略参数-strategy_args">策略参数 (<strong>strategy_args</strong>)<a href="#策略参数-strategy_args" class="hash-link" aria-label="Direct link to 策略参数-strategy_args" title="Direct link to 策略参数-strategy_args">​</a></h3><ul><li><code>strategy_args.strategy_name</code>: 训练/推理策略的名称。<ul><li>用于训练的策略有：<code>deepspeed_train</code>（使用 DeepSpeed）或 <code>megatron_train</code>（使用 Megatron-LM）。</li><li>用于推理的策略有：<code>vllm</code>、<code>sglang</code> 或 <code>hf_infer</code>（使用 Hugging Face 的默认推理）。</li></ul></li><li><code>strategy_args.strategy_config</code>: 训练/推理策略的详细配置，它将作为参数传递给 <code>strategy_name</code>对应的构造函数。例如，<code>strategy_config.tensor_model_parallel_size</code> 用于 <code>megatron_train</code> 策略，<code>strategy_config.gpu_memory_utilization</code> 用于 <code>vllm</code> 策略。</li></ul><p>以下列出了常用的策略配置：</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="megatron-策略配置">Megatron 策略配置<a href="#megatron-策略配置" class="hash-link" aria-label="Direct link to Megatron 策略配置" title="Direct link to Megatron 策略配置">​</a></h4><ul><li><code>tensor_model_parallel_size</code>: 张量模型并行度。将模型的层内（例如矩阵乘法）的计算和内存分割到多个 GPU 上。</li><li><code>pipeline_model_parallel_size</code>: 流水线模型并行度。将模型的不同层或层组分配到不同的 GPU 上，形成一个流水线，以并行处理不同批次的数据。</li><li><code>expert_model_parallel_size</code>: : 专家模型并行度。在 Mixture-of-Experts (MoE) 模型中，将不同的专家（expert）分配到不同的 GPU 上。</li><li><code>context_parallel_size</code>: 上下文并行度。 一种用于处理超长序列的并行策略，将序列分割后并行处理。</li><li><code>virtual_pipeline_model_parallel_size</code>: 流水线中的虚拟流水线数量。用于改善流水线并行的效率和负载均衡。</li><li><code>sequence_parallel</code>: 启用序列并行优化。针对 Transformer 模型中的序列处理进行优化，减少通信开销。</li><li><code>recompute_granularity</code>: 激活值重计算粒度。用于内存优化，在反向传播时重新计算激活值以节省显存。<ul><li>full: 整个 Transformer 层都会被重新计算。</li><li>selective: 仅重新计算 Transformer 层中的核心注意力部分。</li></ul></li><li><code>moe_layer_recompute</code>: 内存优化，对 MoE 层进行检查点以节省激活内存。</li><li><code>moe_token_dispatcher_type</code>: 使用的 token 调度器类型，选项有 &#x27;allgather&#x27; 和 &#x27;alltoall&#x27;。</li><li><code>moe_grouped_gemm</code>: 为 MoE 专家启用分组 GEMM (通用矩阵乘法)。</li><li><code>moe_shared_expert_overlap</code>: 启用共享专家计算与调度器通信之间的重叠。</li><li><code>overlap_grad_reduce</code>: 如果为 true，在分布式优化器中，将梯度 All-reduce 过程与反向传播计算重叠。</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="vllm-策略配置">VLLM 策略配置<a href="#vllm-策略配置" class="hash-link" aria-label="Direct link to VLLM 策略配置" title="Direct link to VLLM 策略配置">​</a></h4><ul><li><code>gpu_memory_utilization</code>: 用于模型执行器的 GPU 内存占比。 例如 0.6 表示使用 60% 的 GPU 内存。</li><li><code>block_size</code>: token 块大小，用于连续的 token 块。影响 VLLM 内部的内存管理效率。</li><li><code>max_model_len</code>: 模型上下文长度。如果未指定，将从模型配置中自动推导。</li><li><code>load_format</code>: 加载模型权重的格式。由于模型会在开始时进行“更新”，此值可以设置为 dummy。</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="sglang-策略配置">SGLang 策略配置<a href="#sglang-策略配置" class="hash-link" aria-label="Direct link to SGLang 策略配置" title="Direct link to SGLang 策略配置">​</a></h4><ul><li><code>mem_fraction_static</code>: 用于模型权重和 KV 缓存等静态内存的 GPU 内存占比。 如果 KV 缓存构建失败，请增加此值；如果 CUDA 内存不足，请减小此值。</li><li><code>load_format</code>: 加载模型权重的格式。（同 VLLM，可设为 dummy）</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="deepspeed-策略配置">DeepSpeed 策略配置<a href="#deepspeed-策略配置" class="hash-link" aria-label="Direct link to DeepSpeed 策略配置" title="Direct link to DeepSpeed 策略配置">​</a></h4><p>在<code>./examples/config/</code> 中有 DeepSpeed 配置文件，可以在默认列表中重写以进行策略配置。
例如，要使用 deepspeed_zero2 策略，请将以下内容添加到您的配置中：</p><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">defaults</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> ../config/envs@_here_</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> ../config/deepspeed_zero@_here_</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> ../config/deepspeed_zero2@_here_   </span><span class="token comment" style="color:#999988;font-style:italic"># 引入 deepspeed_zero2 策略配置</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> ../config/deepspeed_zero3@_here_</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> ../config/deepspeed_zero3_cpuoffload@_here_</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">actor_train</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">strategy_args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> deepspeed_train</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">strategy_config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">deepspeed_zero2</span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="训练参数-training_args">训练参数 (<strong>training_args</strong>)<a href="#训练参数-training_args" class="hash-link" aria-label="Direct link to 训练参数-training_args" title="Direct link to 训练参数-training_args">​</a></h3><p>用于配置训练参数，例如<code>learning_rate</code>(学习率)、<code>weight_decay</code>(权重衰减)、<code>warmup_steps</code>(预热步数) 等。</p><ul><li><code>training_args.per_device_train_batch_size</code>: 在每个设备上进行训练时使用的批次大小。</li><li><code>training_args.gradient_accumulation_steps</code>: 梯度累积的步数。</li></ul><p>在 DeepSpeed 训练中，全局训练批次大小是<code>per_device_train_batch_size</code> <!-- -->*<!-- --> <code>gradient_accumulation_steps</code> <!-- -->*<!-- --> world_size (即<code>actor_train</code>/<code>critic</code>的<code>device_mapping</code>长度)。</p><p>在 Megatron 训练中，全局训练批次大小是<code>per_device_train_batch_size</code> <!-- -->*<!-- --> <code>gradient_accumulation_steps</code> <!-- -->*<!-- --> world_size / <code>tensor_model_parallel_size</code> / <code>pipeline_model_parallel_size</code> / <code>context_parallel_size</code> (不需要除以<code>expert_model_parallel_size</code>).</p><p>如果你想在每次 Rollout 中执行一次优化步骤，则应设置<code>gradient_accumulation_steps</code>为 <code>rollout_batch_size</code> <!-- -->*<!-- --> <code>num_return_sequences_in_group</code> <!-- -->*<!-- --> <code>tensor_model_parallel_size</code> <!-- -->*<!-- --> <code>pipeline_model_parallel_size</code> <!-- -->*<!-- --> <code>context_parallel_size</code>/ <code>per_device_train_batch_size</code> / world_size.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/简体中文/快速开始/config_guide_cn.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ROLL/docs/English/StepByStep/rlvr_pipeline_start"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">RLVR Pipeline</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ROLL/docs/简体中文/快速开始/metrics_info_cn"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">实验数据分析与查看</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#pipeline配置" class="table-of-contents__link toc-highlight">Pipeline配置</a><ul><li><a href="#基本信息与通用配置" class="table-of-contents__link toc-highlight">基本信息与通用配置</a></li><li><a href="#训练评估流程配置" class="table-of-contents__link toc-highlight">训练/评估流程配置</a></li><li><a href="#批处理大小与序列长度配置" class="table-of-contents__link toc-highlight">批处理大小与序列长度配置</a></li><li><a href="#分布式训练配置" class="table-of-contents__link toc-highlight">分布式训练配置</a></li><li><a href="#调度与请求管理" class="table-of-contents__link toc-highlight">调度与请求管理</a></li><li><a href="#rlvr-pipeline-常用配置" class="table-of-contents__link toc-highlight">RLVR Pipeline 常用配置</a></li><li><a href="#agentic-pipeline-配置" class="table-of-contents__link toc-highlight">Agentic Pipeline 配置</a></li></ul></li><li><a href="#worker配置" class="table-of-contents__link toc-highlight">Worker配置</a><ul><li><a href="#actortrainactorinfercriticreference" class="table-of-contents__link toc-highlight">ActorTrain/ActorInfer/Critic/Reference</a></li><li><a href="#模型参数-model_args" class="table-of-contents__link toc-highlight">模型参数 (<strong>model_args</strong>)</a></li><li><a href="#数据参数-data_args" class="table-of-contents__link toc-highlight">数据参数 (<strong>data_args</strong>)</a></li><li><a href="#生成参数-generating_args" class="table-of-contents__link toc-highlight">生成参数 (<strong>generating_args</strong>)</a></li><li><a href="#策略参数-strategy_args" class="table-of-contents__link toc-highlight">策略参数 (<strong>strategy_args</strong>)</a></li><li><a href="#训练参数-training_args" class="table-of-contents__link toc-highlight">训练参数 (<strong>training_args</strong>)</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Examples</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ROLL/docs/简体中文/快速开始/single_node_quick_start_cn">ROLL单机实践手册</a></li><li class="footer__item"><a class="footer__link-item" href="/ROLL/docs/简体中文/快速开始/config_guide_cn">配置指南</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/alibaba/ROLL" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Alibaba.</div></div></div></footer></div>
<script src="/ROLL/assets/js/runtime~main.09d68117.js"></script>
<script src="/ROLL/assets/js/main.b3aa004e.js"></script>
</body>
</html>